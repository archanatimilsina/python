# model running +new things 
dataset comes built-in with scikit-learn

âœ… What scikit-learn built-in datasets are for

Scikit-learn provides built-in datasets mainly for:

âœ” Learning / practicing

Quick experiments

Tutorials

Trying models fast

âœ” Testing algorithms

Benchmarking

Comparing model performance quickly

âœ… What scikit-learn does

Scikit-learn is mainly for:

âœ” Model training

Linear Regression

Logistic Regression

SVM

Decision Trees

Random Forest

âœ” Preprocessing

Scaling

Encoding

Imputation

âœ” Evaluation

MSE, R2, accuracy, etc.

X = Features (Input data) = data.data

This is the data that the model uses to predict something.

y = Target (Output data) = data.target

This is the value the model is trying to predict.

âœ… By default, train_test_split is random

So the split is randomly selected, not the first 80% rows.
```
train_test_split(X, y, test_size=0.2, random_state=42)
```

ğŸ”’ What does random_state=42 mean?

It makes the split reproducible.

If you run the code multiple times with the same random_state, you will get the same split every time.


âœ… Why fit_transform is used on train, and transform on test
Because the test data must NOT influence the training process.
ğŸ”¥ The Key Idea
Training data defines the rules

Example: scaling uses mean and standard deviation.

Test data must follow the same rules

We apply the same scaling learned from training data.

âœ… What does fit do?

fit learns parameters from the data.

Example with StandardScaler:

scaler.fit(X_train)


This calculates:

mean of each column

standard deviation of each column

These are stored inside the scaler.

âœ… What does transform do?

transform applies the learned rules to the data.

Example:

X_train_scaled = scaler.transform(X_train)


This uses the mean and std from training data and scales the data.


âœ… Two main types of scaling
1) Min-Max Scaling (0 to 1)

This is what most people think of when they hear â€œscalingâ€.

Formula:

Xscaled=Xâˆ’XminXmaxâˆ’Xmin
X
scaled
	â€‹

=
X
max
	â€‹

âˆ’X
min
	â€‹

Xâˆ’X
min
	â€‹

	â€‹


This is done using:

from sklearn.preprocessing import MinMaxScaler

2) Standard Scaling (Mean = 0, Std = 1)

This is what StandardScaler does.

Formula:

Xscaled=Xâˆ’Î¼Ïƒ
X
scaled
	â€‹

=
Ïƒ
Xâˆ’Î¼
	â€‹


Where:

Î¼ = mean

Ïƒ = standard deviation

So it does not scale to 0â€“1.

It scales to a distribution where:

mean becomes 0

standard deviation becomes 1


2) Fit + Transform the training data
X_train_scaled = scaler.fit_transform(X_train)


This line does two things:

fit â†’ learn mean & std from X_train

transform â†’ apply scaling using that mean & std

So after this line, the scaler has learned the rules.

3) Transform the test data
X_test_scaled = scaler.transform(X_test)


Here, you only transform, using the rules already learned from training data.